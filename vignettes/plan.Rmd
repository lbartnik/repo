---
title: "Upgrading the Research Toolkit"
author: "Lukasz A. Bartnik"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Upgrading the Research Toolkit}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
library(knitr)

knitr::opts_chunk$set(collapse = TRUE, comment = "#>", prompt = FALSE, echo = TRUE)
```

# Abstract

**Short-term design principle** is to simplify the occasional recall.
By recall we understand the ability to understand the origin or meaning
of a research artifact: data set, code, plot, model, etc[^recall]. In
the schematic view of exploratory data analysis[^dsloop] (see plot XX)
we aim to support the *Communicate* part.

We track the lineage of all artifacts created in the *Explore* loop and
we make the full explanation of their origin readily available upon user
request. Such artifact repository will be valuable whenever there is a
gap in the documentation of the analysis.

**Long-term goals** are to provide infrastructure and tools to automate
certain (semi-)manual tasks, like collecting, describing or organizing
artifacts. An important aspect of that work will be extending the current
text-only user interface with a graphical artifact browser.

[^recall]: Jim Hester: "The ability of yourself or other to understand what your code is doing."

[^dsloop]: Hadley Wickham, "R for Data Science", http://r4ds.had.co.nz/explore-intro.html

# Introduction

![Exploratory data science, diagram from "R for Data Science" by Hadley Wickham.](graphics/data-science-explore.png)

In data exploration we search for new value: understanding which can be
turned into actions. In the process, we create numerous artifacts: plots,
models, derived data sets, tables, printouts. Our success to some extent
depends on our ability to filter, organize and preserve those artifacts
which will further the investigation and later serve as an explanation
of our findings or help in building the narrative about new insights.
An important aspect of said narrative is the lineage of an artifact,
that is, explanation of its origin often as a sequence of transforms
leading from the source data set to that artifact. The ability to track
the origin of an artifact and prove its correctness is important enough
to be a separate discipline, namely *reproducible research*.

The task of cataloguing artifacts imposes certain overhead and if not
done systematically, might omit parts of the lineage. In some cases this
means that the final findings of research are not reproducible. In less
severe cases, it only slows down the research or requires extra work to
recreate missing steps.

The goal of the `repository` package, along with its additional tooling,
is to automate the process of collecting artifacts together wth their
lineage. The life of a repository of artifacts spans multiple R sessions
as the repository is stored in the filesystem. All artifacts can be read
and inspected, as can be their lineage which includes intermediate
artifacts and R expressions that created them. The repository comes with
a search interface.

The extent to which this will be a useful tool depends on how well one
manages the artifacts and the narrative of their exploratory data analysis.
If they do a good job at documenting their research and making it
reproducible, then automated collection might be only occasionally
useful. If, however, they leave certain gaps in their documentation and
often lose parts of the lineage, having an automated tracker might turn
out helpful.


# Future

## Graphical browser

Full inspection into history based on both expressions (commands) and
objects (artifacts) created by those expressions.


(e.g. JS app inside Shiny/RStudio) to effectively browse and work with the repository of artifacts.


## Propose narratives

Identify the parts of the loop: ETL, exploration, models, model summary.
Might be called a *result*.

## Export to Rmd

## Full information about R session

